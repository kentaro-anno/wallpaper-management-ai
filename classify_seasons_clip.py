import os
import sys
import logging
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from functools import partial

import numpy as np
import pandas as pd
import torch
from PIL import Image, ImageDraw, ImageFont
from tqdm import tqdm
from transformers import CLIPProcessor, CLIPModel
import matplotlib.pyplot as plt
import argparse
import shutil

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("season_classifier.log", mode="w", encoding="utf-8")
    ]
)
logger = logging.getLogger(__name__)

# === è¨­å®š ===
DEFAULT_IMAGE_FOLDER = "./images"
DESKTOP = os.path.join(os.environ.get("USERPROFILE", os.path.expanduser("~")), "Desktop")
DEFAULT_OUTPUT_FOLDER = f"{DESKTOP}/classified_images"
BASE_CSV_NAME = "clip_season_analysis.csv"  # åŸºæœ¬çš„ãªåˆ†æçµæœã‚’ä¿å­˜ã™ã‚‹ CSV

SEASON_LABELS = [
    "a photo of spring",
    "a photo of summer",
    "a photo of autumn",
    "a photo of winter"
]

SEASON_FOLDERS = {
    "a photo of spring": "spring",
    "a photo of summer": "summer",
    "a photo of autumn": "autumn",
    "a photo of winter": "winter",
    "unknown": "unknown"
}

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œ
def setup_japanese_fonts():
    try:
        import japanize_matplotlib
        logger.info("japanize_matplotlib ã‚’ä½¿ç”¨ã—ã¦æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®šã—ã¾ã—ãŸã€‚")
        return True
    except ImportError:
        logger.warning("japanize_matplotlib ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install japanize-matplotlib ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
        try:
            plt.rcParams['font.family'] = 'IPAGothic'
            logger.info("IPAGothic ãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®šã—ã¾ã—ãŸã€‚")
            return True
        except:
            logger.warning("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¡¨ç¤ºãŒæ–‡å­—åŒ–ã‘ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            return False

# === ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰ ===
def load_model():
    logger.info("CLIP ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    start_time = time.time()
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32", use_fast=False)
    
    elapsed_time = time.time() - start_time
    logger.info(f"ãƒ‡ãƒã‚¤ã‚¹: {device}, ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚(æ‰€è¦æ™‚é–“: {elapsed_time:.2f}ç§’)")
    return model, processor, device

# === ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢è¨ˆç®—é–¢æ•° ===
def calculate_uncertainty_scores(probs):
    """
    ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
    
    Args:
        probs: ç¢ºç‡åˆ†å¸ƒã®é…åˆ—
        
    Returns:
        dict: å„ç¨®ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢
    """
    # ã‚½ãƒ¼ãƒˆã—ãŸç¢ºç‡åˆ†å¸ƒ
    sorted_probs = np.sort(probs)[::-1]
    
    # 1. æœ€å°ç¢ºä¿¡åº¦ (1 - æœ€å¤§ç¢ºç‡)
    least_confidence = 1.0 - sorted_probs[0]
    
    # 2. ç¢ºä¿¡åº¦ãƒãƒ¼ã‚¸ãƒ³ (æœ€å¤§ç¢ºç‡ - ï¼’ç•ªç›®ã®ç¢ºç‡)
    margin_confidence = sorted_probs[0] - sorted_probs[1]
    
    # 3. ç¢ºä¿¡åº¦æ¯”ç‡ (ï¼’ç•ªç›®ã®ç¢ºç‡ / æœ€å¤§ç¢ºç‡)
    ratio_confidence = sorted_probs[1] / sorted_probs[0] if sorted_probs[0] > 0 else 1.0
    
    # 4. ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
    # 0 ã®ç¢ºç‡ãŒã‚ã‚‹å ´åˆã¯ log(0) ã‚’é¿ã‘ã‚‹ãŸã‚ã®å°ã•ãªå€¤ã‚’è¿½åŠ 
    epsilon = 1e-10
    entropy = -np.sum(probs * np.log(probs + epsilon))
    
    return {
        "least_confidence": least_confidence,
        "margin_confidence": margin_confidence,
        "ratio_confidence": ratio_confidence,
        "entropy": entropy
    }

# === ä¸ç¢ºå®Ÿæ€§ã®åˆ¤å®šã‚’è¡Œã†é–¢æ•° ===
def is_uncertain(value, metric, threshold):
    """
    ä¸ç¢ºå®Ÿæ€§ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°
    
    Args:
        value: ä¸ç¢ºå®Ÿæ€§ã®å€¤
        metric: ä¸ç¢ºå®Ÿæ€§ã®æŒ‡æ¨™
        threshold: é–¾å€¤
        
    Returns:
        bool: ä¸ç¢ºå®Ÿã‹ã©ã†ã‹
    """
    if metric == "margin_confidence":
        # margin_confidence ã¯å°ã•ã„ã»ã©ä¸ç¢ºå®Ÿ
        return value < threshold
    else:
        # ä»–ã®æŒ‡æ¨™ã¯å¤§ãã„ã»ã©ä¸ç¢ºå®Ÿ
        return value > threshold

# === åˆ†é¡å‡¦ç† ===
def analyze_image(image_path, model, processor, device):
    """
    ç”»åƒã‚’åˆ†æã—ã€å­£ç¯€ã‚’äºˆæ¸¬ã™ã‚‹é–¢æ•°
    
    Args:
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        model: CLIPãƒ¢ãƒ‡ãƒ«
        processor: CLIPãƒ—ãƒ­ã‚»ãƒƒã‚µ
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹
        
    Returns:
        tuple: (ç”»åƒ, äºˆæ¸¬ãƒ©ãƒ™ãƒ«, ç¢ºç‡, ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢)
    """
    try:
        image = Image.open(image_path).convert("RGB")
    except FileNotFoundError:
        logger.error(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
        return None, None, None, None
    except PermissionError:
        logger.error(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“: {image_path}")
        return None, None, None, None
    except Exception as e:
        logger.error(f"ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {image_path} ({e})")
        return None, None, None, None
    
    try:
        inputs = processor(text=SEASON_LABELS, images=image, return_tensors="pt", padding=True).to(device)
        with torch.no_grad():  # æ¨è«–æ™‚ã¯å‹¾é…è¨ˆç®—ä¸è¦
            outputs = model(**inputs)
        probs = outputs.logits_per_image.softmax(dim=1).detach().cpu().numpy()[0]
        top_idx = probs.argmax()
        
        # ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        uncertainty_scores = calculate_uncertainty_scores(probs)
        
        return image, SEASON_LABELS[top_idx], probs, uncertainty_scores
    except Exception as e:
        logger.error(f"ç”»åƒã®åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {image_path} ({e})")
        return None, None, None, None

# === ç”»åƒã«æƒ…å ±ã‚’è¿½åŠ ã™ã‚‹é–¢æ•° ===
def add_text_to_image(image, label, probs, uncertainty_scores, uncertainty_metric):
    """
    ç”»åƒã«åˆ†æçµæœã®ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¿½åŠ ã™ã‚‹é–¢æ•°
    
    Args:
        image: å…ƒã®ç”»åƒ
        label: äºˆæ¸¬ãƒ©ãƒ™ãƒ«
        probs: ç¢ºç‡åˆ†å¸ƒ
        uncertainty_scores: ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢
        uncertainty_metric: ä½¿ç”¨ã™ã‚‹ä¸ç¢ºå®Ÿæ€§æŒ‡æ¨™
        
    Returns:
        Image: ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ãŒè¿½åŠ ã•ã‚ŒãŸç”»åƒ
    """
    # å…ƒã®ç”»åƒã‚µã‚¤ã‚ºã‚’å–å¾—
    width, height = image.size
    
    # æ–°ã—ã„ç”»åƒã‚µã‚¤ã‚ºï¼ˆä¸‹éƒ¨ã«ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’è¿½åŠ ï¼‰
    new_height = height + 60  # ãƒ†ã‚­ã‚¹ãƒˆç”¨ã«60ãƒ”ã‚¯ã‚»ãƒ«è¿½åŠ 
    new_image = Image.new("RGB", (width, new_height), (255, 255, 255))
    new_image.paste(image, (0, 0))
    
    # æç”»ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    draw = ImageDraw.Draw(new_image)
    
    # ãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šï¼ˆã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ï¼‰
    font = get_font(16)
    
    # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’ä¸€è¡Œã«ã¾ã¨ã‚ã¦è¿½åŠ 
    y_position = height + 10
    
    # åˆ¤å®šçµæœã¨å­£ç¯€ã‚¹ã‚³ã‚¢
    season_name = label.split()[-1]
    season_scores = " | ".join([f"{name.split()[-1]}: {prob:.3f}" for name, prob in zip(SEASON_LABELS, probs)])
    result_text = f"åˆ¤å®š: {season_name} | {season_scores}"
    draw.text((10, y_position), result_text, fill=(0, 0, 0), font=font)
    y_position += 25
    
    # ä¸ç¢ºå®Ÿæ€§ã‚¹ã‚³ã‚¢ï¼ˆä½¿ç”¨ã—ãŸæŒ‡æ¨™ã‚’å¼·èª¿è¡¨ç¤ºï¼‰
    uncertainty_text = " | ".join([
        f"{metric}: {value:.3f}" + ("*" if metric == uncertainty_metric else "") 
        for metric, value in uncertainty_scores.items()
    ])
    uncertainty_text = f"ä¸ç¢ºå®Ÿæ€§: {uncertainty_text} (*=ä½¿ç”¨æŒ‡æ¨™)"
    draw.text((10, y_position), uncertainty_text, fill=(0, 0, 0), font=font)
    
    return new_image

# === ãƒ•ã‚©ãƒ³ãƒˆã‚’å–å¾—ã™ã‚‹é–¢æ•° ===
def get_font(size=16):
    """
    ã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’å–å¾—ã™ã‚‹é–¢æ•°
    
    Args:
        size: ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
        
    Returns:
        ImageFont: ãƒ•ã‚©ãƒ³ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®ãƒ‘ã‚¹ã‚’æŒ‡å®šï¼ˆç’°å¢ƒã«ã‚ˆã£ã¦ç•°ãªã‚‹ï¼‰
    font_paths = [
        '/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W4.ttc',  # macOS
        '/usr/share/fonts/truetype/fonts-japanese-gothic.ttf',  # Ubuntu
        'C:/Windows/Fonts/meiryo.ttc',  # Windows
        'C:/Windows/Fonts/msgothic.ttc',  # Windows
        '/usr/share/fonts/truetype/ipafont/ipagp.ttf',  # Linux
    ]
    
    for path in font_paths:
        try:
            return ImageFont.truetype(path, size)
        except:
            continue
    
    # ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨
    return ImageFont.load_default()

# === ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆé–¢æ•°ï¼ˆç”»åƒæ•°ã‚’å«ã‚€ï¼‰ ===
def create_output_folders(base_output_folder, uncertainty_metric, uncertainty_threshold):
    """
    å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã™ã‚‹é–¢æ•°
    
    Args:
        base_output_folder: åŸºæœ¬å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        uncertainty_metric: ä¸ç¢ºå®Ÿæ€§æŒ‡æ¨™
        uncertainty_threshold: é–¾å€¤
        
    Returns:
        str: ä½œæˆã—ãŸãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
    """
    # ã€Œä¸ç¢ºå®Ÿæ€§æŒ‡æ¨™_é–¾å€¤ã€ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
    metric_folder_name = f"{uncertainty_metric}_{uncertainty_threshold}"
    output_folder = os.path.join(base_output_folder, metric_folder_name)
    
    # å­£ç¯€ã”ã¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼ˆã“ã®æ™‚ç‚¹ã§ã¯ç”»åƒæ•°ã¯ä¸æ˜ãªã®ã§ã€å¾Œã§åå‰ã‚’æ›´æ–°ï¼‰
    for folder_name in SEASON_FOLDERS.values():
        folder_path = os.path.join(output_folder, folder_name)
        os.makedirs(folder_path, exist_ok=True)
    
    logger.info(f"å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã—ãŸ: {output_folder.replace('\\', '/')}" )
    return output_folder

# === ãƒ•ã‚©ãƒ«ãƒ€åã‚’æ›´æ–°ã™ã‚‹é–¢æ•°ï¼ˆç”»åƒæ•°ã‚’å«ã‚ã‚‹ï¼‰ ===
def update_folder_names(output_folder, folder_counts):
    """
    ãƒ•ã‚©ãƒ«ãƒ€åã‚’æ›´æ–°ã—ã¦ç”»åƒæ•°ã‚’å«ã‚ã‚‹é–¢æ•°
    
    Args:
        output_folder: å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        folder_counts: ãƒ•ã‚©ãƒ«ãƒ€ã”ã¨ã®ç”»åƒæ•°
    """
    for folder_name, count in folder_counts.items():
        old_path = os.path.join(output_folder, folder_name)
        new_folder_name = f"{folder_name} ({count})"
        new_path = os.path.join(output_folder, new_folder_name)
        
        # æ—¢ã«ç”»åƒæ•°ã‚’å«ã‚€ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å‰Šé™¤
        if os.path.exists(new_path) and old_path != new_path:
            shutil.rmtree(new_path)
        
        # ãƒ•ã‚©ãƒ«ãƒ€åã‚’å¤‰æ›´ï¼ˆåŒã˜åå‰ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        if old_path != new_path and os.path.exists(old_path):
            os.rename(old_path, new_path)
            logger.info(f"ãƒ•ã‚©ãƒ«ãƒ€åã‚’æ›´æ–°: {folder_name} â†’ {new_folder_name} ({new_path.replace('\\', '/')})")

# === ç”»åƒã‚’åˆ†æã—ã¦ CSV ã«ä¿å­˜ã™ã‚‹é–¢æ•° ===
def analyze_images(image_folder, base_output_folder, force_recalculate=False, max_workers=4):
    """
    ç”»åƒã‚’åˆ†æã—ã¦çµæœã‚’CSVã«ä¿å­˜ã™ã‚‹é–¢æ•°
    
    Args:
        image_folder: å…¥åŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        base_output_folder: å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        force_recalculate: å¼·åˆ¶å†è¨ˆç®—ãƒ•ãƒ©ã‚°
        max_workers: ä¸¦åˆ—å‡¦ç†ã®æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
        
    Returns:
        DataFrame: åˆ†æçµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    # åŸºæœ¬CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    csv_path = os.path.join(base_output_folder, BASE_CSV_NAME)
    
    # CSV ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã€å¼·åˆ¶å†è¨ˆç®—ãƒ•ãƒ©ã‚°ãŒ False ã®å ´åˆ
    if os.path.exists(csv_path) and not force_recalculate:
        logger.info(f"æ—¢å­˜ã®åˆ†æçµæœ CSV ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {csv_path.replace('\\', '/')}" )
        return pd.read_csv(csv_path)
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    model, processor, device = load_model()
    
    # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆï¼ˆãªã‘ã‚Œã°ï¼‰
    os.makedirs(base_output_folder, exist_ok=True)
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—
    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    if not image_files:
        logger.warning(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_folder}")
        return None
    
    logger.info(f"{len(image_files)} æšã®ç”»åƒã‚’åˆ†æã—ã¦ã„ã¾ã™...")
    
    results = []
    
    # ç”»åƒåˆ†æé–¢æ•°ã‚’ãƒ‘ãƒ¼ã‚·ãƒ£ãƒ«é©ç”¨ã—ã¦ä¸¦åˆ—å‡¦ç†ç”¨ã«æº–å‚™
    analyze_func = partial(analyze_single_image, 
                          image_folder=image_folder, 
                          model=model, 
                          processor=processor, 
                          device=device)
    
    # ä¸¦åˆ—å‡¦ç†ã§ç”»åƒã‚’åˆ†æ
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        for result in tqdm(executor.map(analyze_func, image_files), total=len(image_files)):
            if result is not None:
                results.append(result)
    
    # çµæœã‚’CSVã«ä¿å­˜
    if results:
        df = pd.DataFrame(results)
        df.to_csv(csv_path, index=False)
        
        logger.info(f"\nâœ… åˆ†æå®Œäº†ï¼çµæœã¯ {csv_path.replace('\\', '/')} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        return df
    else:
        logger.warning("åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return None

# === å˜ä¸€ç”»åƒã‚’åˆ†æã™ã‚‹é–¢æ•°ï¼ˆä¸¦åˆ—å‡¦ç†ç”¨ï¼‰ ===
def analyze_single_image(filename, image_folder, model, processor, device):
    """
    å˜ä¸€ã®ç”»åƒã‚’åˆ†æã™ã‚‹é–¢æ•°ï¼ˆä¸¦åˆ—å‡¦ç†ç”¨ï¼‰
    
    Args:
        filename: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å
        image_folder: å…¥åŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        model: CLIPãƒ¢ãƒ‡ãƒ«
        processor: CLIPãƒ—ãƒ­ã‚»ãƒƒã‚µ
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹
        
    Returns:
        dict: åˆ†æçµæœ
    """
    image_path = os.path.join(image_folder, filename)
    image, label, probs, uncertainty_scores = analyze_image(image_path, model, processor, device)
    
    if image is not None:
        # çµæœã‚’è¨˜éŒ²
        return {
            "filename": filename,
            "predicted_label": label,
            "spring": probs[0],
            "summer": probs[1],
            "autumn": probs[2],
            "winter": probs[3],
            "least_confidence": uncertainty_scores["least_confidence"],
            "margin_confidence": uncertainty_scores["margin_confidence"],
            "ratio_confidence": uncertainty_scores["ratio_confidence"],
            "entropy": uncertainty_scores["entropy"]
        }
    return None

# === CSV ã‹ã‚‰ç”»åƒã‚’åˆ†é¡ã™ã‚‹é–¢æ•° ===
def classify_images(df, image_folder, base_output_folder, uncertainty_threshold, uncertainty_metric, max_workers=4, annotate=False, annotate_size=None):
    """
    CSVã‹ã‚‰ç”»åƒã‚’åˆ†é¡ã™ã‚‹é–¢æ•°
    
    Args:
        df: åˆ†æçµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        image_folder: å…¥åŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        base_output_folder: å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        uncertainty_threshold: ä¸ç¢ºå®Ÿæ€§ã®é–¾å€¤
        uncertainty_metric: ä¸ç¢ºå®Ÿæ€§ã®æŒ‡æ¨™
        max_workers: ä¸¦åˆ—å‡¦ç†ã®æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
        annotate: ç”»åƒã«ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¿½åŠ ã™ã‚‹ã‹ã©ã†ã‹
        annotate_size: --annotateæ™‚ã®å‡ºåŠ›ç”»åƒã‚µã‚¤ã‚º (ä¾‹: 1280x720)
        
    Returns:
        tuple: (å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹, åˆ†é¡çµæœã®ãƒªã‚¹ãƒˆ)
    """
    # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆ
    output_folder = create_output_folders(base_output_folder, uncertainty_metric, uncertainty_threshold)
    
    logger.info(f"{len(df)} æšã®ç”»åƒã‚’åˆ†é¡ã—ã¦ã„ã¾ã™...")
    logger.info(f"ä¸ç¢ºå®Ÿæ€§æŒ‡æ¨™: {uncertainty_metric}, é–¾å€¤: {uncertainty_threshold}")
    
    # ä¸ç¢ºå®Ÿæ€§ã®åˆ¤å®š
    if uncertainty_metric == "margin_confidence":
        # margin_confidence ã¯å°ã•ã„ã»ã©ä¸ç¢ºå®Ÿ
        df["is_uncertain"] = df[uncertainty_metric] < uncertainty_threshold
    else:
        # ä»–ã®æŒ‡æ¨™ã¯å¤§ãã„ã»ã©ä¸ç¢ºå®Ÿ
        df["is_uncertain"] = df[uncertainty_metric] > uncertainty_threshold
    
    # åˆ†é¡çµæœã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆ
    classification_results = []
    
    # ãƒ•ã‚©ãƒ«ãƒ€ã”ã¨ã®ç”»åƒæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ãŸã‚ã®è¾æ›¸
    folder_counts = {folder: 0 for folder in SEASON_FOLDERS.values()}
    
    # annotateæ™‚ã¯æŒ‡å®šã‚µã‚¤ã‚º or ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µã‚¤ã‚º
    pad_width, pad_height = None, None
    if annotate:
        if annotate_size:
            pad_width, pad_height = annotate_size
        else:
            pad_width, pad_height = 1920, 1080
    # annotateæ™‚ã¯å…¨ç”»åƒã®ä¸­å¤®å€¤ã‚µã‚¤ã‚ºã‚’å–å¾—
    """
    pad_width, pad_height = None, None
    if annotate:
        sizes = []
        for filename in df["filename"].tolist():
            image_path = os.path.join(image_folder, filename)
            if os.path.exists(image_path):
                with Image.open(image_path) as img:
                    sizes.append(img.size)
        if sizes:
            widths = [w for w, h in sizes]
            heights = [h for w, h in sizes]
            widths.sort()
            heights.sort()
            mid = len(widths) // 2
            pad_width = widths[mid]
            pad_height = heights[mid]
    """
    # åˆ†é¡å‡¦ç†é–¢æ•°ã‚’ãƒ‘ãƒ¼ã‚·ãƒ£ãƒ«é©ç”¨ã—ã¦ä¸¦åˆ—å‡¦ç†ç”¨ã«æº–å‚™
    classify_func = partial(classify_single_image, 
                           df=df, 
                           image_folder=image_folder, 
                           output_folder=output_folder, 
                           uncertainty_metric=uncertainty_metric,
                           uncertainty_threshold=uncertainty_threshold,
                           annotate=annotate,
                           pad_width=pad_width,
                           pad_height=pad_height)
    
    # ä¸¦åˆ—å‡¦ç†ã§ç”»åƒã‚’åˆ†é¡
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        filenames = df["filename"].tolist()
        for result in tqdm(executor.map(classify_func, filenames), total=len(filenames)):
            if result:
                classification_result, target_folder = result
                classification_results.append(classification_result)
                folder_counts[target_folder] += 1
    
    # ãƒ•ã‚©ãƒ«ãƒ€åã‚’æ›´æ–°ï¼ˆç”»åƒæ•°ã‚’å«ã‚ã‚‹ï¼‰
    update_folder_names(output_folder, folder_counts)
    
    # åˆ†é¡çµæœã‚’ CSV ã«ä¿å­˜
    if classification_results:
        classification_df = pd.DataFrame(classification_results)
        classification_csv_path = os.path.join(base_output_folder, f"classification_{uncertainty_metric}_{uncertainty_threshold}.csv")
        classification_df.to_csv(classification_csv_path, index=False)
        logger.info(f"åˆ†é¡çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {classification_csv_path.replace('\\', '/')}" )
    
    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    print_statistics(df, uncertainty_metric, folder_counts, uncertainty_threshold)
    
    logger.info(f"âœ… åˆ†é¡å®Œäº†ï¼åˆ†é¡ã•ã‚ŒãŸç”»åƒã¯ {output_folder.replace('\\', '/')} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    
    return output_folder, classification_results

# === unknown ã«åˆ†é¡ã•ã‚ŒãŸç”»åƒã‚’è¨ºæ–­ã™ã‚‹é–¢æ•° ===
def diagnose_unknown(df, image_folder, uncertainty_metric, uncertainty_threshold):
    """
    unknown ã«åˆ†é¡ã•ã‚ŒãŸç”»åƒã®åŸå› ã‚’ç‰¹å®šã™ã‚‹é–¢æ•°
    
    Args:
        df: åˆ†æçµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        image_folder: å…¥åŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        uncertainty_metric: ä¸ç¢ºå®Ÿæ€§ã®æŒ‡æ¨™
        uncertainty_threshold: ä¸ç¢ºå®Ÿæ€§ã®é–¾å€¤
    """
    # ä¸ç¢ºå®Ÿæ€§ã®åˆ¤å®š
    if uncertainty_metric == "margin_confidence":
        df["is_uncertain"] = df[uncertainty_metric] < uncertainty_threshold
    else:
        df["is_uncertain"] = df[uncertainty_metric] > uncertainty_threshold
    
    # unknown ã«åˆ†é¡ã•ã‚ŒãŸç”»åƒ
    unknown_df = df[df["is_uncertain"] == True].copy()
    
    if len(unknown_df) == 0:
        print(f"âœ… unknown ã«åˆ†é¡ã•ã‚ŒãŸç”»åƒã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆé–¾å€¤: {uncertainty_threshold}ï¼‰")
        return
    
    print(f"\nğŸ“Š unknown åˆ†æï¼ˆé–¾å€¤: {uncertainty_threshold}ã€æŒ‡æ¨™: {uncertainty_metric}ï¼‰")
    print(f"ç· {len(unknown_df)} æšã®ç”»åƒãŒ unknown ã«åˆ†é¡ã•ã‚Œã¦ã„ã¾ã™\n")
    
    # unknown ç”»åƒã®æƒ…å ±ã‚’è¡¨ç¤º
    print(f"{'ãƒ•ã‚¡ã‚¤ãƒ«å':<50} {'åˆ¤å®š':<10} {'ç¢ºç‡':<8} {uncertainty_metric:<15}")
    print("-" * 90)
    
    for idx, row in unknown_df.iterrows():
        filename = row["filename"]
        prediction = row["prediction"]
        max_prob = row["max_prob"]
        metric_value = row[uncertainty_metric]
        print(f"{filename:<50} {prediction:<10} {max_prob:<8.4f} {metric_value:<15.4f}")
    
    # ç•°ãªã‚‹é–¾å€¤ã§ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    print(f"\n\nğŸ” é–¾å€¤å¤‰æ›´ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print(f"ç¾åœ¨ã®è¨­å®š: {uncertainty_metric} = {uncertainty_threshold}\n")
    
    test_thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
    
    print(f"{'é–¾å€¤':<10} {'unknown':<15} {'åˆ¤å®šå¤‰æ›´ç”»åƒ':<20} {'èª¬æ˜'}")
    print("-" * 70)
    
    for test_threshold in test_thresholds:
        if uncertainty_metric == "margin_confidence":
            test_uncertain = (df[uncertainty_metric] < test_threshold).sum()
        else:
            test_uncertain = (df[uncertainty_metric] > test_threshold).sum()
        
        changed = abs(test_uncertain - len(unknown_df))
        
        if test_threshold == uncertainty_threshold:
            marker = " â† ç¾åœ¨"
        else:
            marker = ""
        
        print(f"{test_threshold:<10.1f} {test_uncertain:<15} {changed:<20} {marker}")
    
    # å„å­£ç¯€ã”ã¨ã®å¹³å‡ä¿¡é ¼åº¦
    print(f"\n\nğŸ“ˆ å­£ç¯€ã”ã¨ã®çµ±è¨ˆ")
    print(f"{'å­£ç¯€':<15} {'å¹³å‡ç¢ºç‡':<15} {'å¹³å‡{}'.format(uncertainty_metric):<20}")
    print("-" * 50)
    
    for season_label in SEASON_LABELS:
        season_name = SEASON_FOLDERS[season_label]
        season_df = df[df["prediction"] == season_label]
        if len(season_df) > 0:
            avg_prob = season_df["max_prob"].mean()
            avg_metric = season_df[uncertainty_metric].mean()
            print(f"{season_name:<15} {avg_prob:<15.4f} {avg_metric:<20.4f}")
    
    print("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ: unknown ãŒå¤šã„å ´åˆã¯ã€é–¾å€¤ã‚’ä¸Šã’ã‚‹ï¼ˆä¸ç¢ºå®Ÿæ€§ã‚’é«˜ãï¼‰ã“ã¨ã§æ¸›ã‚‰ã›ã¾ã™ã€‚")

# === unknown ã‚’æœ€å°åŒ–ã™ã‚‹æœ€é©ãªé–¾å€¤ã‚’è¦‹ã¤ã‘ã‚‹é–¢æ•° ===
def find_optimal_threshold(df, uncertainty_metric):
    """
    unknown ã‚’æœ€å°åŒ–ã™ã‚‹æœ€é©ãªé–¾å€¤ã‚’è¦‹ã¤ã‘ã‚‹é–¢æ•°
    
    Args:
        df: åˆ†æçµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        uncertainty_metric: ä¸ç¢ºå®Ÿæ€§ã®æŒ‡æ¨™
        
    Returns:
        tuple: (æœ€é©ãªé–¾å€¤, unknown ã®æœ€å°æ•°)
    """
    test_thresholds = np.arange(0.0, 1.01, 0.05)
    best_threshold = 0.5
    min_unknown_count = len(df)
    
    print(f"\nğŸ” æœ€é©é–¾å€¤ã‚’æ¢ç´¢ä¸­...ï¼ˆæŒ‡æ¨™: {uncertainty_metric}ï¼‰")
    print(f"{'é–¾å€¤':<10} {'unknownæ•°':<15} {'ç‡':<10}")
    print("-" * 35)
    
    for threshold in test_thresholds:
        if uncertainty_metric == "margin_confidence":
            uncertain = (df[uncertainty_metric] < threshold).sum()
        else:
            uncertain = (df[uncertainty_metric] > threshold).sum()
        
        rate = (uncertain / len(df)) * 100
        
        # unknown ãŒæœ€ã‚‚å°‘ãªã„é–¾å€¤ã‚’è¨˜éŒ²
        if uncertain < min_unknown_count:
            min_unknown_count = uncertain
            best_threshold = threshold
        
        marker = " â† æœ€é©" if uncertain == min_unknown_count else ""
        print(f"{threshold:<10.2f} {uncertain:<15} {rate:<10.1f}%{marker}")
    
    return best_threshold, min_unknown_count

# === å˜ä¸€ç”»åƒã‚’åˆ†é¡ã™ã‚‹é–¢æ•°ï¼ˆä¸¦åˆ—å‡¦ç†ç”¨ï¼‰ ===
def classify_single_image(filename, df, image_folder, output_folder, uncertainty_metric, uncertainty_threshold, annotate=False, pad_width=None, pad_height=None):
    """
    å˜ä¸€ã®ç”»åƒã‚’åˆ†é¡ã™ã‚‹é–¢æ•°ï¼ˆä¸¦åˆ—å‡¦ç†ç”¨ï¼‰
    
    Args:
        filename: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å
        df: åˆ†æçµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        image_folder: å…¥åŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        output_folder: å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        uncertainty_metric: ä¸ç¢ºå®Ÿæ€§ã®æŒ‡æ¨™
        uncertainty_threshold: ä¸ç¢ºå®Ÿæ€§ã®é–¾å€¤
        annotate: ç”»åƒã«ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¿½åŠ ã™ã‚‹ã‹ã©ã†ã‹
        pad_width: å‡ºåŠ›ç”»åƒã®å¹…
        pad_height: å‡ºåŠ›ç”»åƒã®é«˜ã•
        
    Returns:
        tuple: (åˆ†é¡çµæœ, ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ã‚©ãƒ«ãƒ€)
    """
    image_path = os.path.join(image_folder, filename)
    
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        if not os.path.exists(image_path):
            logger.warning(f"è­¦å‘Š: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
            return None
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰è©²å½“è¡Œã‚’å–å¾—
        row = df[df["filename"] == filename].iloc[0]
        
        # å…ƒã®ç”»åƒã‚’èª­ã¿è¾¼ã‚€
        image = Image.open(image_path).convert("RGB")
        
        # annotateæ™‚ã¯ä¸­å¤®å€¤ã‚µã‚¤ã‚ºã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        if annotate and pad_width and pad_height:
            w, h = image.size
            new_img = Image.new("RGB", (pad_width, pad_height), (255, 255, 255))
            left = (pad_width - w) // 2
            top = (pad_height - h) // 2
            new_img.paste(image, (left, top))
            image = new_img
        
        # ä¸ç¢ºå®Ÿæ€§ãŒé–¾å€¤ã‚’è¶…ãˆã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        is_uncertain_flag = row["is_uncertain"]
        
        # ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®æ±ºå®š
        if is_uncertain_flag:
            target_folder = "unknown"
        else:
            target_folder = SEASON_FOLDERS[row["predicted_label"]]
        
        # ç”»åƒã«æƒ…å ±ã‚’è¿½åŠ 
        probs = [row["spring"], row["summer"], row["autumn"], row["winter"]]
        uncertainty_scores = {
            "least_confidence": row["least_confidence"],
            "margin_confidence": row["margin_confidence"],
            "ratio_confidence": row["ratio_confidence"],
            "entropy": row["entropy"]
        }
        
        output_path = os.path.join(output_folder, target_folder, filename)
        if annotate:
            annotated_image = add_text_to_image(image, row["predicted_label"], probs, uncertainty_scores, uncertainty_metric)
            annotated_image.save(output_path)
        else:
            image.save(output_path)
        
        # åˆ†é¡çµæœã‚’è¨˜éŒ²
        classification_result = {
            "filename": filename,
            "predicted_label": row["predicted_label"],
            "classified_folder": target_folder,
            "is_uncertain": is_uncertain_flag,
            "uncertainty_value": row[uncertainty_metric],
            "uncertainty_metric": uncertainty_metric,
            "uncertainty_threshold": uncertainty_threshold
        }
        
        return classification_result, target_folder
        
    except FileNotFoundError:
        logger.error(f"ã‚¨ãƒ©ãƒ¼: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
    except PermissionError:
        logger.error(f"ã‚¨ãƒ©ãƒ¼: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“: {image_path}")
    except Exception as e:
        logger.error(f"ã‚¨ãƒ©ãƒ¼: ç”»åƒ {filename} ã®å‡¦ç†ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    return None

# === çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•° ===
def print_statistics(df, uncertainty_metric, folder_counts, uncertainty_threshold):
    """
    çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
    
    Args:
        df: åˆ†æçµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        uncertainty_metric: ä¸ç¢ºå®Ÿæ€§ã®æŒ‡æ¨™
        folder_counts: ãƒ•ã‚©ãƒ«ãƒ€ã”ã¨ã®ç”»åƒæ•°
        uncertainty_threshold: ä¸ç¢ºå®Ÿæ€§ã®é–¾å€¤
    """
    logger.info("\n=== åˆ†é¡çµæœ ===")
    for folder_name, count in folder_counts.items():
        logger.info(f"{folder_name}: {count} æš")
    
    # ä¸ç¢ºå®Ÿæ€§æŒ‡æ¨™ã®çµ±è¨ˆæƒ…å ±
    logger.info(f"\n=== ä¸ç¢ºå®Ÿæ€§æŒ‡æ¨™ã€Œ{uncertainty_metric}ã€ã®çµ±è¨ˆ ===")
    logger.info(f"å¹³å‡å€¤: {df[uncertainty_metric].mean():.4f}")
    logger.info(f"ä¸­å¤®å€¤: {df[uncertainty_metric].median():.4f}")
    logger.info(f"æœ€å°å€¤: {df[uncertainty_metric].min():.4f}")
    logger.info(f"æœ€å¤§å€¤: {df[uncertainty_metric].max():.4f}")
    logger.info(f"é–¾å€¤: {uncertainty_threshold:.4f}")
    
    # å­£ç¯€ã”ã¨ã®ä¸ç¢ºå®Ÿæ€§ã®å¹³å‡
    logger.info("\n=== å­£ç¯€ã”ã¨ã®ä¸ç¢ºå®Ÿæ€§å¹³å‡ ===")
    for season in SEASON_LABELS:
        season_name = season.split()[-1]
        season_df = df[df["predicted_label"] == season]
        if len(season_df) > 0:
            # ä¸ç¢ºå®Ÿæ€§ã®åˆ¤å®š
            if uncertainty_metric == "margin_confidence":
                uncertain_count = sum(season_df[uncertainty_metric] < uncertainty_threshold)
            else:
                uncertain_count = sum(season_df[uncertainty_metric] > uncertainty_threshold)
                
            logger.info(f"{season_name}: {season_df[uncertainty_metric].mean():.4f} (å…¨ {len(season_df)} æšä¸­ã€ä¸ç¢ºå®Ÿ {uncertain_count} æš)")

# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===
def main(image_folder, base_output_folder, uncertainty_threshold=0.5, uncertainty_metric="entropy", 
         force_recalculate=False, analyze_only=False, max_workers=4, annotate=False, annotate_size=None, diagnose_unknown_mode=False, auto_mode=False):
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•°
    
    Args:
        image_folder: å…¥åŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        base_output_folder: å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        uncertainty_threshold: ä¸ç¢ºå®Ÿæ€§ã®é–¾å€¤
        uncertainty_metric: ä¸ç¢ºå®Ÿæ€§ã®æŒ‡æ¨™
        force_recalculate: å¼·åˆ¶å†è¨ˆç®—ãƒ•ãƒ©ã‚°
        analyze_only: åˆ†æã®ã¿ãƒ•ãƒ©ã‚°
        max_workers: ä¸¦åˆ—å‡¦ç†ã®æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
        annotate: ç”»åƒã«ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¿½åŠ ã™ã‚‹ã‹ã©ã†ã‹
        annotate_size: --annotateæ™‚ã®å‡ºåŠ›ç”»åƒã‚µã‚¤ã‚º (ä¾‹: 1280x720)
        diagnose_unknown_mode: unknownè¨ºæ–­ãƒ¢ãƒ¼ãƒ‰
        auto_mode: è‡ªå‹•æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰
        
    Returns:
        tuple: (åˆ†æçµæœã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ , å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹, åˆ†é¡çµæœã®ãƒªã‚¹ãƒˆ)
    """
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
    setup_japanese_fonts()
    
    # ç”»åƒã®åˆ†æï¼ˆCSV ãŒãªã‘ã‚Œã°å®Ÿè¡Œï¼‰
    df = analyze_images(image_folder, base_output_folder, force_recalculate, max_workers)
    
    if df is None:
        logger.error("ç”»åƒã®åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return None
    
    # diagnose-unknown ãƒ¢ãƒ¼ãƒ‰ãªã‚‰å®Ÿè¡Œ
    if diagnose_unknown_mode:
        diagnose_unknown(df, image_folder, uncertainty_metric, uncertainty_threshold)
        return df, None, None
    
    # auto ãƒ¢ãƒ¼ãƒ‰ãªã‚‰æœ€é©é–¾å€¤ã‚’è¦‹ã¤ã‘ã¦å®Ÿè¡Œ
    if auto_mode:
        optimal_threshold, min_unknown = find_optimal_threshold(df, uncertainty_metric)
        logger.info(f"\nâœ… æœ€é©é–¾å€¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {optimal_threshold:.2f}ï¼ˆunknownæ•°: {min_unknown}ï¼‰")
        uncertainty_threshold = optimal_threshold
    
    # åˆ†æã®ã¿ã®ãƒ¢ãƒ¼ãƒ‰ãªã‚‰çµ‚äº†
    if analyze_only:
        logger.info("åˆ†æã®ã¿ãƒ¢ãƒ¼ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¾ã—ãŸã€‚åˆ†é¡ã¯è¡Œã„ã¾ã›ã‚“ã€‚")
        return df, None, None
    
    # ç”»åƒã®åˆ†é¡
    output_folder, classification_results = classify_images(
        df, image_folder, base_output_folder, uncertainty_threshold, uncertainty_metric, max_workers, annotate, annotate_size
    )
    
    return df, output_folder, classification_results

# === CLI å¼•æ•°å¯¾å¿œ ===
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å­£ç¯€ã”ã¨ã«ç”»åƒã‚’åˆ†é¡ã—ã€ä¸ç¢ºå®Ÿãªç”»åƒã‚’ç‰¹å®šã—ã¾ã™")
    parser.add_argument("--folder", type=str, default=DEFAULT_IMAGE_FOLDER, help="å…¥åŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹")
    parser.add_argument("--output", type=str, default=DEFAULT_OUTPUT_FOLDER, help="å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹")
    parser.add_argument("--uncertainty-threshold", type=float, default=0.5, help="ä¸ç¢ºå®Ÿæ€§ã®é–¾å€¤")
    parser.add_argument("--uncertainty-metric", type=str, default="entropy", 
                        choices=["least_confidence", "margin_confidence", "ratio_confidence", "entropy"],
                        help="ä¸ç¢ºå®Ÿæ€§ã®æŒ‡æ¨™")
    parser.add_argument("--force", action="store_true", help="æ—¢å­˜ã® CSV ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã£ã¦ã‚‚å¼·åˆ¶çš„ã«å†åˆ†æã™ã‚‹")
    parser.add_argument("--analyze-only", action="store_true", help="åˆ†æã®ã¿ã‚’è¡Œã„ã€åˆ†é¡ã¯è¡Œã‚ãªã„")
    parser.add_argument("--workers", type=int, default=4, help="ä¸¦åˆ—å‡¦ç†ã®æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°")
    parser.add_argument("--debug", action="store_true", help="ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹ã«ã™ã‚‹")
    parser.add_argument("--annotate", action="store_true", help="ç”»åƒã«åˆ¤å®šçµæœã‚„æŒ‡æ¨™ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ã™ã‚‹")
    parser.add_argument("--annotate-size", type=str, default=None, help="--annotateæ™‚ã®å‡ºåŠ›ç”»åƒã‚µã‚¤ã‚º (ä¾‹: 1280x720)")
    parser.add_argument("--diagnose-unknown", action="store_true", help="unknown ã«åˆ†é¡ã•ã‚ŒãŸç”»åƒã®åŸå› ã‚’è¨ºæ–­ã™ã‚‹")
    parser.add_argument("--auto", action="store_true", help="unknown ã‚’æœ€å°åŒ–ã™ã‚‹æœ€é©ãªé–¾å€¤ã‚’è‡ªå‹•ã§è¦‹ã¤ã‘ã¦åˆ†é¡ã™ã‚‹")
    
    args = parser.parse_args()
    
    # --auto ã¨ --diagnose-unknown ã¯åŒæ™‚ã«ä½¿ãˆãªã„
    if args.auto and args.diagnose_unknown:
        logger.error("--auto ã¨ --diagnose-unknown ã¯åŒæ™‚ã«ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
        sys.exit(1)
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®š
    if args.debug:
        logger.setLevel(logging.DEBUG)
        logger.debug("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã—ãŸ")
    
    try:
        # annotate-sizeã®ãƒ‘ãƒ¼ã‚¹
        annotate_size = None
        if args.annotate_size:
            try:
                w, h = args.annotate_size.lower().split('x')
                annotate_size = (int(w), int(h))
            except Exception:
                logger.warning(f"--annotate-size ã®å½¢å¼ãŒä¸æ­£ã§ã™: {args.annotate_size}")
        main(args.folder, args.output, args.uncertainty_threshold, args.uncertainty_metric, 
             args.force, args.analyze_only, args.workers, args.annotate, annotate_size, args.diagnose_unknown, args.auto)
    except KeyboardInterrupt:
        logger.info("å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
        sys.exit(1)
    except Exception as e:
        logger.exception(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)
